{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "editable": true,
    "id": "GUvdvAaASzmD",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Lab 03: Cây quyết định"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Họ tên:\n",
    "- MSSV:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**LƯU Ý:**</font>\n",
    "\n",
    "- Bài làm của sinh viên phải do chính bản thân sinh viên tự làm, có thể trao đổi và tham khảo ý tưởng nhưng không được sao chép (một phần hoặc toàn bộ) code hoặc lời giải từ bất cứ người nào khác. Nếu vi phạm sẽ bị <font color='red'>0đ</font> bài tập này.\n",
    "- Các bạn có thể tạo thêm các cell trong quá trình code, tuy nhiên các bạn vui lòng <font color='red'>không xóa các cell code mặc định và các cell test case</font> (vì có thể ảnh hưởng đến kết quả khi chấm bài).\n",
    "- Các test case được đưa ra chỉ nhằm mục đích giúp các bạn test code của mình, <font color='red'>**việc pass các test case này không đồng nghĩa với việc lời giải của các bạn sẽ đạt điểm tối đa**</font>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cách làm bài**\n",
    "\n",
    "\n",
    "Bạn sẽ làm trực tiếp trên file notebook này; trong file, từ `TODO` để cho biết những phần mà bạn cần phải làm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Cách nộp bài**\n",
    "\n",
    "Khi chấm bài, đầu tiên mình sẽ chọn `Kernel` - `Restart Kernel & Run All Cells`, để restart và chạy tất cả các cell trong notebook của các bạn; do đó, trước khi nộp bài, các bạn nên chạy thử `Kernel` - `Restart Kernel & Run All Cells` để đảm bảo mọi chuyện diễn ra đúng như mong đợi.\n",
    "\n",
    "Sau đó, các bạn tạo thư mục nộp bài theo cấu trúc sau:\n",
    "\n",
    "- Thư mục `MSSV` (vd, nếu bạn có MSSV là 1234567 thì bạn đặt tên thư mục là `1234567`)\n",
    "    - File `HW03.ipynb` (Đổi tên file notebook này theo MSSV của bạn)\n",
    "\n",
    "Cuối cùng, các bạn nén thư mục `MSSV` này lại và nộp ở link trên moodle. **Đuôi của file nén phải là .zip (chứ không được .rar hay gì khác).**\n",
    "\n",
    "<font color=red>Các bạn lưu ý tuân thủ chính xác qui định nộp bài ở trên.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nội dung bài tập**\n",
    "\n",
    "Bài tập 3 là bài tập cá nhân. Trong bài này, bạn sẽ cài đặt thuật toán học máy: \n",
    "1. Cây quyết định (Decision tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lYefhgwoSzmZ"
   },
   "source": [
    "### Tải những thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXTmvF6JSzmb"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from zlib import adler32\n",
    "from typing import Tuple, List\n",
    "import requests\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import sklearn.datasets as datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init seed\n",
    "seed = 2024\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tải tập dữ liệu về thuốc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hãy tưởng tượng rằng bạn là một nhà nghiên cứu y khoa đang biên soạn dữ liệu cho một nghiên cứu. Bạn đã thu thập dữ liệu về một nhóm bệnh nhân, tất cả đều mắc cùng một căn bệnh. Trong quá trình điều trị, mỗi bệnh nhân đều đáp ứng với một trong 5 loại thuốc, Thuốc A, Thuốc B, Thuốc c, Thuốc x và thuốc y.\n",
    "\n",
    "Một phần công việc của bạn là xây dựng một mô hình để tìm ra loại thuốc nào có thể phù hợp với bệnh nhân tương lai mắc cùng một căn bệnh. Các đặc điểm của tập dữ liệu này là Tuổi, Giới tính, Huyết áp và Cholesterol của bệnh nhân, và mục tiêu là loại thuốc mà mỗi bệnh nhân đáp ứng.\n",
    "\n",
    "Đây là một mẫu của bộ phân loại đa lớp và bạn có thể sử dụng tập dữ liệu để xây dựng một cây quyết định, sau đó sử dụng nó để dự đoán lớp của một bệnh nhân chưa biết hoặc kê đơn thuốc cho một bệnh nhân mới."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CO6JKObwSzmn"
   },
   "source": [
    "### Đọc tập dữ liệu về thuốc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viết hàm `drug_dataloader` để load tập dữ liệu từ tập tin `drug200_numeric.csv` và trả về hai mảng numpy array `features` và `classes` đại diện cho đặc trưng và lớp tương ứng. Lưu ý, không sử Pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "6EFp9Jl3Szmo",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "354fea915de738db30523ac01a77fa1b",
     "grade": false,
     "grade_id": "cell-b51e0c5b09e4fd07",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def drug_dataloader(file_path=\"drug200_numeric.csv\"):\n",
    "    # YOUR CODE HERE\n",
    "    features = []\n",
    "    classes = []\n",
    "    with open(file_path, \"r\") as file:\n",
    "        # Skip the header line\n",
    "        next(file)\n",
    "        for line in file.readlines():\n",
    "            data = line.strip().split(',')\n",
    "            features.append([float(value) for value in data[:-1]])\n",
    "            classes.append(int(data[-1]))\n",
    "    features = np.array(features)\n",
    "    classes = np.array(classes)\n",
    "    \n",
    "    #raise NotImplementedError()\n",
    "    return features, classes\n",
    "\n",
    "features, classes = drug_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2319320757\n"
     ]
    }
   ],
   "source": [
    "print(adler32(str(features[0][:5] + features[1][:5] + features[2][:5]).encode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afffa7add37e0f58ecdc8d91648ceff6",
     "grade": true,
     "grade_id": "cell-a6cc5f408a498169",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TEST\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m----> 3\u001b[0m     adler32(\u001b[38;5;28mstr\u001b[39m(features[\u001b[38;5;241m0\u001b[39m][:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m+\u001b[39m features[\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m+\u001b[39m features[\u001b[38;5;241m2\u001b[39m][:\u001b[38;5;241m5\u001b[39m])\u001b[38;5;241m.\u001b[39mencode())\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1140262165\u001b[39m\n\u001b[0;32m      5\u001b[0m )\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "assert (\n",
    "    adler32(str(features[0][:5] + features[1][:5] + features[2][:5]).encode())\n",
    "    == 1140262165\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phân chia tập train-valid-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d75ea90d8d7bf25a287c15a80a269ea",
     "grade": false,
     "grade_id": "cell-a3c318564484782b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((134, 5), (66, 5), (134,), (66,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_test_split(\n",
    "    X: np.ndarray, y: np.ndarray, test_ratio=0.33\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Function for proceduring train, and test sets.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): input features.\n",
    "        y (np.ndarray): input labels.\n",
    "        test_ratio (float, optional): ratio size for test sets. Defaults to 0.33.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]: features, label for train, test respectively. \n",
    "        They are represented as numpy array.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    test_size = int(len(indices) * test_ratio)\n",
    "    test_indices = indices[:test_size]\n",
    "    train_indices = indices[test_size:]\n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_train = y[train_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "\n",
    "    \n",
    "    #raise NotImplementedError()\n",
    "    return (\n",
    "        X_train,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "    )\n",
    "\n",
    "\n",
    "# Phân chia tập train, test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, classes)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "772e01c2c9ac9ab9ae269dd79d9c2064",
     "grade": true,
     "grade_id": "cell-2cc71a102b3df50d",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "SP = X_train.shape + X_test.shape + y_train.shape + y_test.shape\n",
    "assert adler32(str(SP).encode()) == 889979968"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kz-C6eu2Szmt"
   },
   "source": [
    "## Cây quyết định"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UEQ7wvnpSzm3"
   },
   "source": [
    "### Độ lợi thông tin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9doZ5CKSSzm5"
   },
   "source": [
    "Thông tin kỳ vọng (entropy):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KmJNW8LxSzm6"
   },
   "source": [
    "$$Entropy=-\\sum_{i}^{n}p_ilog_{2}(p_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z-H-41plSzm7"
   },
   "source": [
    "Hàm entropy đạt giá trị nhỏ nhất nếu có một giá trị $p_i=1$, đạt giá trị lớn nhất nếu tất cả các $p_i$ bằng nhau. Những tính chất này của hàm entropy khiến nó được sử dụng trong việc đo độ hỗn loạn của một phép phân chia của ID3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "HGAwlg1dSzm9",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c82149b871071c550a9539286c040f7b",
     "grade": false,
     "grade_id": "cell-c917d0fafb4d820c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def entropy(counts: List, n_samples: int) -> float:\n",
    "    \"\"\"Function for calculating entropy\n",
    "\n",
    "    Args:\n",
    "        counts (list): list number of samples in each class.\n",
    "        n_samples (int): number of data samples.\n",
    "\n",
    "    Return:\n",
    "        entropy (float).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    probabilities = [count / n_samples for count in counts if count > 0]\n",
    "    return -sum(p * np.log2(p) for p in probabilities)\n",
    "    # raise NotImplementedError()\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "EJ7on8pvSznN",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "423b4ed2826331d6aa29aad3ad89f92a",
     "grade": false,
     "grade_id": "cell-906add99ae2307c3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def entropy_of_one_division(division: np.ndarray) -> Tuple[float, int]:\n",
    "    \"\"\"Function for calculating entropy of a divided group of data.\n",
    "\n",
    "    Please note that data may have multiple classes.\n",
    "\n",
    "    Args:\n",
    "        division (np.ndarray): input divided group of data.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, int]: entropy of a divided group of data.\n",
    "    \"\"\"\n",
    "    n_samples = len(division)\n",
    "    n_classes = set(division)\n",
    "\n",
    "    counts = []\n",
    "    # count samples in each class then store it to list counts\n",
    "    # YOUR CODE HERE\n",
    "    counts = [np.sum(division == cls) for cls in n_classes]\n",
    "    #raise NotImplementedError()\n",
    "    return entropy(counts, n_samples), n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "3XWpYwi_Lco6",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "efecfb24e1476d3e5d3442da227c0996",
     "grade": false,
     "grade_id": "cell-ddf2eddaec74f262",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_entropy(y_predict: np.ndarray, y: np.ndarray):\n",
    "    \"\"\"Get entropy for a split.\n",
    "\n",
    "    Args:\n",
    "        y_predict (np.ndarray): the split decision by cutoff, True/Fasle.\n",
    "        y (np.ndarray): grouth truth.\n",
    "\n",
    "    Returns:\n",
    "        s (float): entropy of input split, as real-number represented with float type.\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    entropy_true, n_true = entropy_of_one_division(\n",
    "        y[y_predict]\n",
    "    )  # left hand side entropy\n",
    "    \n",
    "    entropy_false, n_false = entropy_of_one_division(\n",
    "        y[~y_predict]\n",
    "    )  # right hand side entropy\n",
    "    # overall entropy\n",
    "    \n",
    "    # s=?\n",
    "    # YOUR CODE HERE\n",
    "    s = (n_true / n) * entropy_true + (n_false / n) * entropy_false\n",
    "    # raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fFI9qoMWSznZ"
   },
   "source": [
    "Độ lợi thông tin phân lớp tập D theo thuộc tính A:\n",
    "$$ Gain(A)=Entropy(D)-Entropy_{A}(D)$$\n",
    "\n",
    "Trong ID3, tại mỗi node, thuộc tính được chọn được xác định dựa trên là thuộc tính khiến cho information gain đạt giá trị lớn nhất.\n",
    "\n",
    "Các thuộc tính của tập Iris đều có giá trị liên tục. Do đó ta cần rời rạc hóa cho từng thuộc tính. Cách đơn giản là sử dụng một ngưỡng `cutoff` chia giá trị của dữ liệu trên mỗi thuộc tính sẽ làm 2 phần: `<cutoff` và `>=cutoff`.\n",
    "\n",
    "Để tìm ngưỡng `cutoff` tốt nhất cho mỗi thuộc tính ta lần lượt thay `cutoff` bằng các giá trị của thuộc tính sau đó tính entropy, `cutoff` tốt nhất khi entropy bé nhất \n",
    "\n",
    "$$\\left(\\arg\\min Entropy_{A}(D)\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sCQvubYDSzna"
   },
   "source": [
    "### Cài đặt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tìm một phân hoạch với một độ lợi thông tin cho trước"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a210b4fbf6c8b48fbb34755d62285624",
     "grade": false,
     "grade_id": "cell-a8b2e0b4ee1a4a63",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def find_best_split(\n",
    "    col_data: np.ndarray, y: np.ndarray\n",
    ") -> Tuple[np.float64, np.float64]:\n",
    "    \"\"\"Function for calculating minimum entropy for a given attributes and its label.\n",
    "\n",
    "    Args:\n",
    "        col_data (np.ndarray): input column data in training dataset.\n",
    "        y (np.ndarray): given label in the training dataset.\n",
    "\n",
    "    Returns:\n",
    "        min_entropy, cutoff (Tuple[np.float64, np.float64]): the minimum entropy, and cut-off value.\n",
    "    \"\"\"\n",
    "    min_entropy = float(\"inf\")\n",
    "    cutoff = None\n",
    "\n",
    "    # Loop through col_data find cutoff where entropy is minimum\n",
    "    for value in set(col_data):\n",
    "        y_predict = col_data < value\n",
    "        my_entropy = get_entropy(y_predict, y)\n",
    "\n",
    "        # min entropy=?, cutoff=?\n",
    "        # YOUR CODE HERE\n",
    "        if my_entropy < min_entropy:\n",
    "            min_entropy = my_entropy\n",
    "            cutoff = value\n",
    "\n",
    "        # raise NotImplementedError()\n",
    "\n",
    "    # Return min entropy, and cutoff\n",
    "    return min_entropy, cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split_of_all(\n",
    "    X: np.ndarray, y: np.ndarray\n",
    ") -> Tuple[np.float64, np.float64, np.float64]:\n",
    "    \"\"\"Function for finding one split given an information gain.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): input training dataset.\n",
    "        y (np.ndarray): given label in the training dataset.\n",
    "\n",
    "    Returns:\n",
    "        col_idx, cutoff, min_entropy (Tuple[np.float64, np.float64, np.float64]): return the index \n",
    "        of column with minimum entropy and cut-off value.\n",
    "    \"\"\"\n",
    "    col_idx = None\n",
    "    min_entropy = float(\"inf\")\n",
    "    cutoff = None\n",
    "\n",
    "    for idx, col_data in enumerate(X.T):\n",
    "        entropy, cur_cutoff = find_best_split(col_data, y)\n",
    "\n",
    "        if entropy == 0:  # best entropy\n",
    "            return idx, cur_cutoff, entropy\n",
    "        elif entropy <= min_entropy:\n",
    "            min_entropy = entropy\n",
    "            col_idx = idx\n",
    "            cutoff = cur_cutoff\n",
    "\n",
    "    return col_idx, cutoff, min_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Khớp dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtfit(X: np.ndarray, y: np.ndarray, depth: int = 0) -> dict:\n",
    "    \"\"\"Function for data-fitting with Decision Tree\n",
    "\n",
    "    Node: each node represented by cutoff value and column index, value and children.\n",
    "         - cutoff value is thresold where you divide your attribute,\n",
    "         - column index is your data attribute index,\n",
    "         - value of node is mean value of label indexes,\n",
    "           if a node is leaf all data samples will have same label.\n",
    "\n",
    "    Note that: we divide each attribute into 2 part => each node will have 2 children: left, right.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): training data\n",
    "        y (np.ndarray): label of training data\n",
    "        depth (int, optional): depth of decision tree after training. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        node (dict): return the node that contains cutoff value and column index, value and children.\n",
    "    \"\"\"\n",
    "    # Stop conditions: if all value of y are the same\n",
    "    if np.all(y == y[0]):\n",
    "        return {\"val\": y[0]}\n",
    "\n",
    "    # find one split given an information gain\n",
    "    col_idx, cutoff, entropy = find_best_split_of_all(X, y)\n",
    "\n",
    "    y_left = y[X[:, col_idx] < cutoff]\n",
    "    y_right = y[X[:, col_idx] >= cutoff]\n",
    "    X_left = X[X[:, col_idx] < cutoff]\n",
    "    X_right = X[X[:, col_idx] >= cutoff]\n",
    "\n",
    "    node = {\n",
    "        \"index_col\": col_idx,\n",
    "        \"cutoff\": cutoff,\n",
    "        \"val\": np.mean(y),\n",
    "        \"left\": None,\n",
    "        \"right\": None,\n",
    "    }\n",
    "\n",
    "    node[\"left\"] = dtfit(X_left, y_left, depth + 1)\n",
    "    node[\"right\"] = dtfit(X_right, y_right, depth + 1)\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Khớp dữ liệu\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tree \u001b[38;5;241m=\u001b[39m \u001b[43mdtfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[44], line 25\u001b[0m, in \u001b[0;36mdtfit\u001b[1;34m(X, y, depth)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m: y[\u001b[38;5;241m0\u001b[39m]}\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# find one split given an information gain\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m col_idx, cutoff, entropy \u001b[38;5;241m=\u001b[39m \u001b[43mfind_best_split_of_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m y_left \u001b[38;5;241m=\u001b[39m y[X[:, col_idx] \u001b[38;5;241m<\u001b[39m cutoff]\n\u001b[0;32m     28\u001b[0m y_right \u001b[38;5;241m=\u001b[39m y[X[:, col_idx] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m cutoff]\n",
      "Cell \u001b[1;32mIn[43], line 19\u001b[0m, in \u001b[0;36mfind_best_split_of_all\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     16\u001b[0m cutoff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, col_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(X\u001b[38;5;241m.\u001b[39mT):\n\u001b[1;32m---> 19\u001b[0m     entropy, cur_cutoff \u001b[38;5;241m=\u001b[39m \u001b[43mfind_best_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m entropy \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# best entropy\u001b[39;00m\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m idx, cur_cutoff, entropy\n",
      "Cell \u001b[1;32mIn[41], line 16\u001b[0m, in \u001b[0;36mfind_best_split\u001b[1;34m(col_data, y)\u001b[0m\n\u001b[0;32m     13\u001b[0m my_entropy \u001b[38;5;241m=\u001b[39m get_entropy(y_predict, y)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Update min entropy and cutoff\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmy_entropy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmin_entropy\u001b[49m:\n\u001b[0;32m     17\u001b[0m     min_entropy \u001b[38;5;241m=\u001b[39m my_entropy\n\u001b[0;32m     18\u001b[0m     cutoff \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "# Khớp dữ liệu\n",
    "tree = dtfit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dự đoán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dtpredict(tree: dict, row: np.ndarray) -> int:\n",
    "    \"\"\"Function for making prediction use trained DT tree on given observation.\n",
    "\n",
    "    Args:\n",
    "        tree (dict): trained DT model which presented as a dict.\n",
    "        row (np.ndarray): given observation which presented as numpy's array.\n",
    "\n",
    "    Returns:\n",
    "        val (int): return the value of node which is mean value of label indexes.\n",
    "    \"\"\"\n",
    "    cur_layer = tree\n",
    "    while \"cutoff\" in cur_layer:\n",
    "        if row[cur_layer[\"index_col\"]] < cur_layer[\"cutoff\"]:\n",
    "            cur_layer = cur_layer[\"left\"]\n",
    "        else:\n",
    "            cur_layer = cur_layer[\"right\"]\n",
    "    return cur_layer.get(\"val\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "282aee67ccd22f460ce05e835feeaafa",
     "grade": true,
     "grade_id": "cell-6b6d83ccf73e5701",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m given_observation \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;241m81\u001b[39m]\n\u001b[0;32m      3\u001b[0m groud_truth \u001b[38;5;241m=\u001b[39m classes[\u001b[38;5;241m81\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m groud_truth \u001b[38;5;241m==\u001b[39m _dtpredict(\u001b[43mtree\u001b[49m, given_observation)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tree' is not defined"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "given_observation = features[81]\n",
    "groud_truth = classes[81]\n",
    "assert groud_truth == _dtpredict(tree, given_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtpredict(tree: dict, data: np.ndarray) -> List:\n",
    "    \"\"\"Function for making prediction with trained DT model on given input observations.\n",
    "\n",
    "    Args:\n",
    "        tree (dict): trained DT model which presented as a dict.\n",
    "        data (np.ndarray): input input observations.\n",
    "\n",
    "    Returns:\n",
    "        pred (List): list of predicted label for input observations.\n",
    "    \"\"\"\n",
    "    pred = []\n",
    "    for _, col in enumerate(data):\n",
    "        pred.append(_dtpredict(tree, col))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5b04c3aec4a04d1b754d2eed25a5c78",
     "grade": true,
     "grade_id": "cell-5b6c8e1cee25bcdc",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "given_observations = features[81:118]\n",
    "groud_truth = classes[81:118]\n",
    "res = (groud_truth == dtpredict(tree, given_observations))\n",
    "assert adler32(str(res).encode()) == 794314306"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đánh giá mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ccf05173d9ca663347f077d197818c3",
     "grade": false,
     "grade_id": "cell-0c2efded71f1bf27",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def tpfptnfn_cal(\n",
    "    y_test: np.ndarray, y_pred: np.ndarray, positive_class: int = 1\n",
    ") -> Tuple[int, int, int, int]:\n",
    "    \"\"\"Function for calculating elements of confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        y_test (np.ndarray): groud truth.\n",
    "        y_pred (np.ndarray): predicted label.\n",
    "        positive_class (int, optional): wanted calculating class. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        true_positives, false_positives, true_negatives, false_negatives (Tuple[int, int, int, int]): Four \n",
    "        basic number for constructing confusion matrix  including true positives, false positives, true negatives, \n",
    "        and false negatives.\n",
    "    \"\"\"\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "\n",
    "    # Calculate true positives, false positives, false negatives, and true negatives\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return true_positives, false_positives, true_negatives, false_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6927cdc8d14b0fbf72e2d450bb396502",
     "grade": true,
     "grade_id": "cell-e812d2f07627ab0f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "tp, fp, tn, fn = tpfptnfn_cal([1, 0, 1, 1, 0, 0, 1], [1, 0, 0, 1, 0, 1, 1])\n",
    "assert adler32((str(tp) + str(fp) + str(tn) + str(fn)).encode()) == 33030344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán\n",
    "pred = dtpredict(tree, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8f7ca840730cc097fa7acd021a62001c",
     "grade": false,
     "grade_id": "cell-dd89c2d2cd33974e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(\n",
    "    y_test: np.ndarray, y_pred: np.ndarray\n",
    ") -> Tuple[float, float, float, float]:\n",
    "    \"\"\"Function for calculating metrics of classification problem including accuracy, recall, \n",
    "    precision, and f1-score.\n",
    "\n",
    "    Args:\n",
    "        y_test (np.ndarray): groud truth.\n",
    "        y_pred (np.ndarray): predicted label.\n",
    "\n",
    "    Returns:\n",
    "        acc, precision, recall, f1 (Tuple[float, float, float, float]): return four values \n",
    "        for each metric: accuracy, recall, precision, and f1-score.\n",
    "    \"\"\"\n",
    "    acc = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "\n",
    "    noc = len(np.unique(y_test))  # number of classes\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9d61f809c4a3483f9cd9d79572d5033",
     "grade": true,
     "grade_id": "cell-57aedef886488c55",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nghiên cứu về ý nghĩa các độ đo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn hãy trình ý nghĩa từng độ đo, bao gồm accuracy, precision, recall và f-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d227affdb00152670052d2054d15cd2",
     "grade": false,
     "grade_id": "cell-6e87e78bdda8212a",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab03-Clustering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
